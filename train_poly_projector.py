#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PCME Eq.(4) - Route A (MC teacher -> polynomial surrogate -> no-sampling training)
Single-file script with 3 modes:
  1) build_teacher:  Monte Carlo to generate teacher dataset for Eq.(4)
  2) fit_poly:       Fit polynomial ridge on (E[D], Var[D]) -> logit(score_mc)
  3) train_poly:     Train projectors using poly logits (NO MC sampling)

Eq.(4) target:
  p(m|x,y) = E_{z_x~N(mu_x,var_x), z_y~N(mu_y,var_y)} [ sigmoid(-a * ||z_x - z_y||^2 + b) ]

We fit a polynomial surrogate on:
  features: (ed = E[D], vd = Var[D]) where D = ||z_x - z_y||^2
  label:    logit( p_mc ) estimated by MC (K samples per side => KxK pairs)

Then training uses:
  logits_ij = Poly(ed_ij, vd_ij)   (approx logit(p(m|x_i,y_j)))
  loss = CE(logits/temperature) + CE(logits^T/temperature)

Notes:
- This script does NOT depend on your original project code besides embedding files.
- It expects emb_text.pt and emb_video.pt (precomputed encoders on GPU side).

Author: (generated by ChatGPT)
"""

import argparse
import json
from pathlib import Path
from dataclasses import dataclass
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm


# -----------------------------
# Projector / Dataset (unchanged)
# -----------------------------
class ProbabilisticProjector(nn.Module):
    def __init__(self, dim=1024, hidden=2048):
        super().__init__()
        self.mu_proj = nn.Sequential(
            nn.Linear(dim, hidden),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden, dim)
        )
        self.logvar_proj = nn.Sequential(
            nn.Linear(dim, hidden),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden, dim)
        )

    def forward(self, x):
        f_mu = self.mu_proj(x)
        mu = x + f_mu               # Residual
        mu = F.normalize(mu, dim=-1)
        logvar = torch.clamp(self.logvar_proj(x), -5, 2)
        return mu, logvar


class EmbeddingDataset(Dataset):
    def __init__(self, text, video):
        self.text = text
        self.video = video

    def __len__(self):
        return len(self.text)

    def __getitem__(self, i):
        return self.text[i], self.video[i]


# -----------------------------
# Math utils: E[D], Var[D] for D = ||z1 - z2||^2
# z1~N(mu1, var1), z2~N(mu2,var2), diag, independent
# -----------------------------
def dist_stats_l2sq_broadcast(mu1, logvar1, mu2, logvar2):
    """
    Broadcastable version.

    mu1/logvar1: [..., D]
    mu2/logvar2: [..., D] broadcastable to mu1

    Returns:
      ed: [...]
      vd: [...]
    """
    var1 = torch.exp(logvar1)
    var2 = torch.exp(logvar2)
    s2 = var1 + var2
    delta = mu1 - mu2
    dim = mu1.shape[-1]

    ed = ((delta * delta).sum(dim=-1) + s2.sum(dim=-1)) / dim
    vd = (2.0 * (s2 * s2).sum(dim=-1) + 4.0 * ((delta * delta) * s2).sum(dim=-1)) / (dim * dim)
    return ed, vd


def dist_stats_l2sq_matrix(t_mu, t_lv, v_mu, v_lv):
    """
    t_*: [B,D], v_*: [B,D] -> ed/vd: [B,B]
    """
    t_mu_e = t_mu.unsqueeze(1)   # [B,1,D]
    t_lv_e = t_lv.unsqueeze(1)
    v_mu_e = v_mu.unsqueeze(0)   # [1,B,D]
    v_lv_e = v_lv.unsqueeze(0)

    ed, vd = dist_stats_l2sq_broadcast(t_mu_e, t_lv_e, v_mu_e, v_lv_e)
    return ed, vd  # [B,B]


# -----------------------------
# MC teacher for Eq.(4)
# -----------------------------
def sample_z(mu, logvar, K):
    """
    mu/logvar: [D] or [1,D]
    returns: [K,D]
    """
    if mu.dim() == 1:
        mu = mu.unsqueeze(0)
        logvar = logvar.unsqueeze(0)
    std = torch.exp(0.5 * logvar)  # [1,D]
    eps = torch.randn(K, mu.size(-1), device=mu.device, dtype=mu.dtype)
    return mu[0] + eps * std[0]


def mc_teacher_score_eq4(mu1, lv1, mu2, lv2, K, a, b):
    """
    Returns scalar p_mc â‰ˆ E[sigmoid(-a*||z1-z2||^2 + b)]
    using K samples per side => KxK distances.
    """
    z1 = sample_z(mu1, lv1, K)   # [K,D]
    z2 = sample_z(mu2, lv2, K)   # [K,D]
    # distances [K,K]
    diff = z1[:, None, :] - z2[None, :, :]
    d2 = (diff * diff).sum(dim=-1)
    p = torch.sigmoid(-a * d2 + b).mean()
    return p


def logit_np(p, eps=1e-6):
    p = np.clip(p, eps, 1.0 - eps)
    return np.log(p / (1.0 - p))


# -----------------------------
# Polynomial surrogate (sklearn in fit stage, torch in train stage)
# -----------------------------
@dataclass
class PolySurrogate:
    degree: int
    coeff: torch.Tensor  # [n_feat]
    bias: float          # scalar
    fit_logit: bool = True  # we fit logit(p)

class LearnablePolySurrogate(nn.Module):
    """
    Learnable polynomial: both coefficients and bias are nn.Parameter, can be trained end-to-end with projector.
    """
    def __init__(self, degree: int, fit_logit: bool = True, init_from: str = None):
        super().__init__()
        self.degree = degree
        self.fit_logit = fit_logit
        n_feat = poly_num_features_2vars(degree)
        
        # Initialization strategy
        if init_from:
            # Initialize from existing poly_coeffs.pt
            ckpt = torch.load(init_from, map_location='cpu', weights_only=False)
            if int(ckpt['degree']) != degree:
                raise ValueError(f"Degree mismatch: init poly has degree {ckpt['degree']}, but requested {degree}")
            self.coeff = nn.Parameter(ckpt['coeff'].float().clone())
            self.bias = nn.Parameter(torch.tensor([float(ckpt['bias'])]))
            print(f"  [init] Initialized poly from {init_from}")
        else:
            # Heuristic initialization: based on Eq.(4) form sigmoid(-a*ed + b)
            # Expect poly â‰ˆ -a*ed + small_noise for reasonable initial ranking
            coeff_init = torch.randn(n_feat) * 0.1
            # First coefficient is ed, give it negative initial value (larger distance = lower similarity)
            coeff_init[0] = -5.0 + torch.randn(1) * 0.5  # ed coefficient
            # Second coefficient is vd (variance), give small positive value
            if n_feat > 1:
                coeff_init[1] = -1.0 + torch.randn(1) * 0.3   # vd coefficient
            self.coeff = nn.Parameter(coeff_init)
            self.bias = nn.Parameter(torch.randn(1) * 0.5)
            print(f"  [init] Heuristic initialization: coeff[0]={self.coeff[0].item():.3f} (ed), coeff[1]={self.coeff[1].item() if n_feat>1 else 'N/A':.3f} (vd), bias={self.bias.item():.3f}")
    
    def forward(self, ed, vd):
        """Return logits â‰ˆ logit(p(m|x,y))"""
        X = poly_features_2vars_sklearn_order(ed, vd, self.degree)  # [..., n_feat]
        logits = (X * self.coeff).sum(dim=-1) + self.bias
        return logits
    
    def to_surrogate(self) -> PolySurrogate:
        """Convert to dataclass format for saving and inference"""
        return PolySurrogate(
            degree=self.degree,
            coeff=self.coeff.detach().cpu(),
            bias=float(self.bias.item()),
            fit_logit=self.fit_logit
        )

def poly_num_features_2vars(degree: int) -> int:
    # sklearn PolynomialFeatures(include_bias=False) for 2 vars
    # number of monomials of total degree 1..degree in 2 vars = C(deg+2,2)-1
    return (degree + 2) * (degree + 1) // 2 - 1

def poly_features_2vars_sklearn_order(ed, vd, degree: int):
    """
    Match sklearn PolynomialFeatures(include_bias=False) for variables [ed, vd]
    Order is:
      deg1: ed, vd
      deg2: ed^2, ed*vd, vd^2
      deg3: ed^3, ed^2*vd, ed*vd^2, vd^3
      ...
    ed,vd can be tensors of any shape, returns [..., n_feat]
    """
    feats = [ed, vd]
    if degree >= 2:
        feats += [ed*ed, ed*vd, vd*vd]
    if degree >= 3:
        feats += [ed**3, (ed**2)*vd, ed*(vd**2), vd**3]
    if degree >= 4:
        feats += [ed**4, (ed**3)*vd, (ed**2)*(vd**2), ed*(vd**3), vd**4]
    if degree >= 5:
        feats += [ed**5, (ed**4)*vd, (ed**3)*(vd**2), (ed**2)*(vd**3), ed*(vd**4), vd**5]
    if degree >= 6:
        feats += [ed**6, (ed**5)*vd, (ed**4)*(vd**2), (ed**3)*(vd**3),
                  (ed**2)*(vd**4), ed*(vd**5), vd**6]
    if degree > 6:
        raise ValueError("For simplicity this demo supports degree<=6. Extend if needed.")
    return torch.stack(feats, dim=-1)

def poly_predict_logits(ed, vd, poly):
    """
    Return logits â‰ˆ logit(p(m|x,y)) for Eq.(4)
    Supports PolySurrogate (dataclass) and LearnablePolySurrogate (nn.Module)
    """
    if isinstance(poly, LearnablePolySurrogate):
        return poly(ed, vd)
    else:
        # PolySurrogate dataclass
        X = poly_features_2vars_sklearn_order(ed, vd, poly.degree)  # [..., n_feat]
        coeff = poly.coeff.to(X.device, dtype=X.dtype)
        logits = (X * coeff).sum(dim=-1) + float(poly.bias)
        return logits


# -----------------------------
# Loss: Eq.(4) poly logits + InfoNCE
# -----------------------------
def pcme_loss_eq4_poly(t_mu, t_lv, v_mu, v_lv, poly, temperature=0.07, n_samples=0):
    """
    Build [B,B] logits matrix via polynomial surrogate:
      logits_ij â‰ˆ logit( E[sigmoid(-a*||z_t - z_v||^2 + b)] )
    Then use it as similarity logits for bidirectional InfoNCE.
    
    Args:
        n_samples: If > 0, use Monte Carlo sampling (like baseline PCME);
                   If = 0, use deterministic (ed, vd) (original way)
    """
    B = t_mu.size(0)
    device = t_mu.device
    
    if n_samples > 0:
        # ðŸ”¥ NEW: Monte Carlo sampling, like baseline
        t_std = torch.exp(0.5 * t_lv)
        v_std = torch.exp(0.5 * v_lv)
        
        total_loss = 0.0
        for _ in range(n_samples):
            # Sampling
            eps_t = torch.randn_like(t_mu)
            eps_v = torch.randn_like(v_mu)
            z_t = t_mu + eps_t * t_std
            z_v = v_mu + eps_v * v_std
            
            # Compute (ed, vd) from samples
            z_t_e = z_t.unsqueeze(1)  # [B,1,D]
            z_v_e = z_v.unsqueeze(0)  # [1,B,D]
            delta = z_t_e - z_v_e     # [B,B,D]
            ed_sample = (delta * delta).sum(dim=-1) / t_mu.size(-1)  # [B,B]
            
            # vd = 0 for sampled points (no uncertainty in samples)
            vd_sample = torch.zeros_like(ed_sample)
            
            # Poly logits
            logits = poly_predict_logits(ed_sample, vd_sample, poly) / temperature
            
            # Loss
            labels = torch.arange(B, device=device)
            total_loss += F.cross_entropy(logits, labels) + F.cross_entropy(logits.t(), labels)
        
        return total_loss / n_samples
    
    else:
        # Original deterministic way
        ed, vd = dist_stats_l2sq_matrix(t_mu, t_lv, v_mu, v_lv)  # [B,B]
        logits = poly_predict_logits(ed, vd, poly)               # [B,B]

        logits = logits / temperature
        labels = torch.arange(B, device=device)
        return F.cross_entropy(logits, labels) + F.cross_entropy(logits.t(), labels)


def mu_contrastive_loss(t_mu, v_mu, temperature=0.07):
    """
    [Training only, not used in CIM inference]
    Standard contrastive (InfoNCE) on mu. Only used during training to constrain projectors,
    makes matching pairs have higher cos(mu_t, mu_v). CIM inference still only does projectorsâ†’(ed,vd)â†’polyâ†’similarity,
    does not do any mu similarity or contrastive computation.
    t_mu, v_mu: [B,D], L2-normalized.
    """
    B = t_mu.size(0)
    device = t_mu.device
    sim = (t_mu @ v_mu.t()) / temperature
    labels = torch.arange(B, device=device)
    return F.cross_entropy(sim, labels) + F.cross_entropy(sim.t(), labels)


# -----------------------------
# Regularization (keep simple)
# -----------------------------
def kl_divergence_loss(mu, logvar):
    return -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())

def variance_upper_bound_loss(logvar, max_var=0.09):
    var = torch.exp(logvar)
    return F.relu(var - max_var).mean()


# -----------------------------
# Mode 1: build_teacher
# -----------------------------
def mode_build_teacher(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)

    emb_dir = getattr(args, 'emb_dir', None)
    npz = getattr(args, 'npz', None)
    if not emb_dir and not npz:
        raise ValueError("build_teacher requires one of --npz or --emb_dir")
    if emb_dir and npz:
        raise ValueError("build_teacher: use only one of --npz or --emb_dir")

    # Support either npz (text_mu/logvar, video_mu/logvar) or pt dir (emb_text.pt, emb_video.pt)
    if emb_dir:
        emb_dir = Path(args.emb_dir)
        if not emb_dir.exists():
            raise FileNotFoundError(f"emb_dir not found: {emb_dir}")
        text_emb = torch.load(emb_dir / 'emb_text.pt', map_location=device, weights_only=False)
        video_emb = torch.load(emb_dir / 'emb_video.pt', map_location=device, weights_only=False)
        if text_emb.dim() != 2 or video_emb.dim() != 2:
            raise ValueError("emb_text.pt and emb_video.pt must be [N, D] tensors")
        text_mu = F.normalize(text_emb.to(device).float(), dim=-1)
        video_mu = F.normalize(video_emb.to(device).float(), dim=-1)
        # Raw embeddings: use as mu, fixed small logvar (no learned variance yet)
        default_logvar = getattr(args, 'default_logvar', -5.0)
        text_lv = torch.full_like(text_mu, default_logvar, device=device)
        video_lv = torch.full_like(video_mu, default_logvar, device=device)
    else:
        data = np.load(args.npz, allow_pickle=True)
        text_mu = torch.tensor(data['text_mu'], dtype=torch.float32, device=device)
        text_lv = torch.tensor(data['text_logvar'], dtype=torch.float32, device=device)
        video_mu = torch.tensor(data['video_mu'], dtype=torch.float32, device=device)
        video_lv = torch.tensor(data['video_logvar'], dtype=torch.float32, device=device)

    Nt = text_mu.size(0)
    Nv = video_mu.size(0)

    out = Path(args.out)
    out.parent.mkdir(parents=True, exist_ok=True)

    ed_arr = np.empty((args.n_pairs,), dtype=np.float32)
    vd_arr = np.empty((args.n_pairs,), dtype=np.float32)
    y_arr  = np.empty((args.n_pairs,), dtype=np.float32)

    pbar = tqdm(range(args.n_pairs), desc="build_teacher (MC Eq4)")
    for i in pbar:
        ti = np.random.randint(0, Nt)
        vi = np.random.randint(0, Nv)

        mu1, lv1 = text_mu[ti], text_lv[ti]
        mu2, lv2 = video_mu[vi], video_lv[vi]

        ed, vd = dist_stats_l2sq_broadcast(mu1, lv1, mu2, lv2)
        ed_arr[i] = float(ed.detach().cpu())
        vd_arr[i] = float(vd.detach().cpu())

        p = mc_teacher_score_eq4(mu1, lv1, mu2, lv2, K=args.K, a=args.a, b=args.b)
        y_arr[i] = float(p.detach().cpu())

    np.savez_compressed(out, ed=ed_arr, vd=vd_arr, y=y_arr, K=args.K, a=args.a, b=args.b)
    print(f"Saved teacher dataset: {out}")


# -----------------------------
# Mode 2: fit_poly
# -----------------------------
def mode_fit_poly(args):
    # sklearn only used here
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.linear_model import Ridge

    d = np.load(args.teacher_npz, allow_pickle=True)
    ed = d['ed'].astype(np.float64)
    vd = d['vd'].astype(np.float64)
    y  = d['y'].astype(np.float64)

    X = np.stack([ed, vd], axis=1)
    poly = PolynomialFeatures(degree=args.degree, include_bias=False)
    Xp = poly.fit_transform(X)

    if args.fit_logit:
        target = logit_np(y)
    else:
        target = y

    model = Ridge(alpha=args.alpha)
    model.fit(Xp, target)

    coeff = model.coef_.astype(np.float32)
    bias  = float(model.intercept_)
    feat_names = poly.get_feature_names_out(['ed','vd'])

    out = Path(args.out)
    out.parent.mkdir(parents=True, exist_ok=True)

    torch.save({
        "degree": args.degree,
        "alpha": args.alpha,
        "fit_logit": args.fit_logit,
        "coeff": torch.tensor(coeff),
        "bias": bias,
        "feature_names": list(feat_names),
        "teacher_meta": {k: (d[k].item() if np.ndim(d[k]) == 0 else None) for k in ['K','a','b'] if k in d}
    }, out)

    print(f"Saved poly coeffs: {out}")
    print(f"  degree={args.degree}, n_feat={coeff.shape[0]} (expected {poly_num_features_2vars(args.degree)})")
    print(f"  bias={bias:.6f}")


# -----------------------------
# Mode 3: train_poly (NO MC)
# -----------------------------
def mode_train_poly(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    emb_dir = Path(args.emb_dir)
    text = torch.load(emb_dir / 'emb_text.pt', weights_only=False)
    video = torch.load(emb_dir / 'emb_video.pt', weights_only=False)
    N = text.shape[0]
    print(f"Loaded embeddings: text={tuple(text.shape)}, video={tuple(video.shape)}")

    dim = text.size(-1)
    text_proj = ProbabilisticProjector(dim, hidden=args.hidden).to(device)
    video_proj = ProbabilisticProjector(dim, hidden=args.hidden).to(device)

    # load polynomial surrogate
    poly_ckpt = torch.load(args.poly_path, map_location='cpu')
    poly = PolySurrogate(
        degree=int(poly_ckpt["degree"]),
        coeff=poly_ckpt["coeff"].float(),
        bias=float(poly_ckpt["bias"]),
        fit_logit=bool(poly_ckpt.get("fit_logit", True)),
    )
    # sanity check
    if poly_num_features_2vars(poly.degree) != poly.coeff.numel():
        raise ValueError(f"Poly coeff size mismatch: got {poly.coeff.numel()} expected {poly_num_features_2vars(poly.degree)} "
                         f"(degree={poly.degree}). If degree>6, extend poly_features_2vars_sklearn_order.")

    params = list(text_proj.parameters()) + list(video_proj.parameters())
    optimizer = torch.optim.AdamW(params, lr=args.lr, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=args.lr * 0.1)

    dataset = EmbeddingDataset(text, video)
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)

    Path(args.save_dir).mkdir(exist_ok=True, parents=True)
    best_loss = float('inf')

    mu_weight = getattr(args, "mu_loss_weight", 0.0)
    print("\nTraining (Eq4 poly, NO MC sampling)")
    print(f"  poly_degree: {poly.degree}")
    print(f"  temperature: {args.temperature}")
    print(f"  mu_loss_weight: {mu_weight} (training only, CIM inference does not use mu)")
    print(f"  var_reg: {args.var_reg_type} (w={args.var_reg_weight})")
    print(f"  epochs={args.epochs}, batch={args.batch_size}, lr={args.lr}\n")

    for epoch in range(args.epochs):
        text_proj.train(); video_proj.train()
        total = 0.0

        pbar = tqdm(loader, desc=f"Epoch {epoch+1}/{args.epochs}")
        for tb, vb in pbar:
            tb = F.normalize(tb.to(device), dim=-1)
            vb = F.normalize(vb.to(device), dim=-1)

            optimizer.zero_grad()
            t_mu, t_lv = text_proj(tb)
            v_mu, v_lv = video_proj(vb)

            # Poly loss (with optional MC sampling)
            n_samples = getattr(args, 'n_samples', 0)
            cont = pcme_loss_eq4_poly(t_mu, t_lv, v_mu, v_lv, poly, 
                                     temperature=args.temperature,
                                     n_samples=n_samples)

            # [Training only] mu contrastive loss: only affects gradients, does not change CIM inference formula. CIM still only computes (ed,vd)â†’poly.
            mu_weight = getattr(args, "mu_loss_weight", 0.0)
            if mu_weight > 0:
                loss_mu = mu_contrastive_loss(t_mu, v_mu, temperature=args.temperature)
                cont = cont + mu_weight * loss_mu

            # variance reg
            if args.var_reg_type == 'kl':
                reg = kl_divergence_loss(t_mu, t_lv) + kl_divergence_loss(v_mu, v_lv)
            elif args.var_reg_type == 'upper_bound':
                reg = variance_upper_bound_loss(t_lv, args.max_var) + variance_upper_bound_loss(v_lv, args.max_var)
            else:
                reg = 0.0

            loss = cont + (args.var_reg_weight * reg if not isinstance(reg, float) else 0.0)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(params, 1.0)
            optimizer.step()

            total += float(loss.detach().cpu())
            pbar.set_postfix(loss=f"{loss.item():.4f}", cont=f"{cont.item():.4f}")

        scheduler.step()
        avg = total / len(loader)
        print(f"Epoch {epoch+1}: avg_loss={avg:.4f}")

        # optional: variance health check (small subset for speed)
        if args.variance_check_every > 0 and (epoch + 1) % args.variance_check_every == 0:
            with torch.no_grad():
                t_in = F.normalize(text[:min(4096, N)].to(device), dim=-1)
                v_in = F.normalize(video[:min(4096, N)].to(device), dim=-1)
                _, t_lv_all = text_proj(t_in)
                _, v_lv_all = video_proj(v_in)
                t_var = torch.exp(t_lv_all).mean().item()
                v_var = torch.exp(v_lv_all).mean().item()
            print(f"  variance_mean: text={t_var:.6f}, video={v_var:.6f}")

        if avg < best_loss:
            best_loss = avg
            torch.save({
                "epoch": epoch,
                "text": text_proj.state_dict(),
                "video": video_proj.state_dict(),
                "loss": best_loss,
                "config": vars(args),
                "poly": {
                    "degree": poly.degree,
                    "coeff": poly.coeff,  # â† Save full coefficients
                    "bias": poly.bias,    # â† Save bias
                    "fit_logit": poly.fit_logit,
                    "coeff_n": int(poly.coeff.numel()),
                }
            }, Path(args.save_dir) / "best_projectors_eq4_poly.pth")
            print("  âœ“ saved best")

    print("Done. best_loss =", best_loss)


# -----------------------------
# Mode 4: train_poly_e2e (end-to-end training of poly coefficients and projector)
# -----------------------------
def mode_train_poly_e2e(args):
    """
    End-to-end training: poly coefficients and projector learn together, no need for build_teacher and fit_poly beforehand.
    
    Training workflow:
    1. Randomly initialize poly coefficients
    2. Each batch: projectors â†’ (Î¼, logvar) â†’ (ed, vd) â†’ poly(ed, vd) â†’ contrastive loss
    3. Update both projector and poly coefficients simultaneously
    
    CIM inference unchanged: projectors â†’ (ed, vd) â†’ poly(ed, vd) â†’ similarity
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    emb_dir = Path(args.emb_dir)
    text = torch.load(emb_dir / 'emb_text.pt', weights_only=False)
    video = torch.load(emb_dir / 'emb_video.pt', weights_only=False)
    N = text.shape[0]
    print(f"Loaded embeddings: text={tuple(text.shape)}, video={tuple(video.shape)}")

    dim = text.size(-1)
    text_proj = ProbabilisticProjector(dim, hidden=args.hidden).to(device)
    video_proj = ProbabilisticProjector(dim, hidden=args.hidden).to(device)
    
    # Create learnable poly (can initialize from existing poly, or use heuristic initialization)
    init_from = getattr(args, 'init_poly', None)
    poly = LearnablePolySurrogate(degree=args.poly_degree, fit_logit=True, init_from=init_from).to(device)
    print(f"Initialized learnable poly: degree={poly.degree}, n_params={sum(p.numel() for p in poly.parameters())}")

    # optimizer includes all parameters of projector + poly
    params = list(text_proj.parameters()) + list(video_proj.parameters()) + list(poly.parameters())
    optimizer = torch.optim.AdamW(params, lr=args.lr, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=args.lr * 0.1)

    dataset = EmbeddingDataset(text, video)
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)

    Path(args.save_dir).mkdir(exist_ok=True, parents=True)
    best_loss = float('inf')

    mu_weight = getattr(args, "mu_loss_weight", 0.0)
    n_samples = getattr(args, 'n_samples', 0)
    init_from = getattr(args, 'init_poly', None)
    print("\nEnd-to-end training (poly coefficients learnable, NO teacher/fit_poly)")
    print(f"  poly_degree: {poly.degree}")
    print(f"  init_poly: {init_from if init_from else 'heuristic initialization'}")
    print(f"  n_samples: {n_samples} ({'Monte Carlo sampling' if n_samples > 0 else 'deterministic training'})")
    print(f"  temperature: {args.temperature}")
    print(f"  mu_loss_weight: {mu_weight} (training only, CIM inference does not use mu)")
    print(f"  var_reg: {args.var_reg_type} (w={args.var_reg_weight})")
    print(f"  epochs={args.epochs}, batch={args.batch_size}, lr={args.lr}\n")

    for epoch in range(args.epochs):
        text_proj.train(); video_proj.train(); poly.train()
        total = 0.0

        pbar = tqdm(loader, desc=f"Epoch {epoch+1}/{args.epochs}")
        for tb, vb in pbar:
            tb = F.normalize(tb.to(device), dim=-1)
            vb = F.normalize(vb.to(device), dim=-1)

            optimizer.zero_grad()
            t_mu, t_lv = text_proj(tb)
            v_mu, v_lv = video_proj(vb)

            # poly loss (poly coefficients also participate in gradients)
            cont = pcme_loss_eq4_poly(t_mu, t_lv, v_mu, v_lv, poly, temperature=args.temperature)

            # [Training only] mu contrastive loss
            if mu_weight > 0:
                loss_mu = mu_contrastive_loss(t_mu, v_mu, temperature=args.temperature)
                cont = cont + mu_weight * loss_mu

            # variance reg
            if args.var_reg_type == 'kl':
                reg = kl_divergence_loss(t_mu, t_lv) + kl_divergence_loss(v_mu, v_lv)
            elif args.var_reg_type == 'upper_bound':
                reg = variance_upper_bound_loss(t_lv, args.max_var) + variance_upper_bound_loss(v_lv, args.max_var)
            else:
                reg = 0.0

            loss = cont + (args.var_reg_weight * reg if not isinstance(reg, float) else 0.0)
            loss.backward()
            optimizer.step()

            total += loss.item()
            pbar.set_postfix(loss=f"{loss.item():.4f}")

        scheduler.step()
        avg = total / len(loader)
        print(f"Epoch {epoch+1}/{args.epochs} loss={avg:.6f}")

        # variance check
        if args.variance_check_every > 0 and (epoch + 1) % args.variance_check_every == 0:
            text_proj.eval(); video_proj.eval()
            with torch.no_grad():
                tb_all = F.normalize(text[:500].to(device), dim=-1)
                vb_all = F.normalize(video[:500].to(device), dim=-1)
                _, t_lv_all = text_proj(tb_all)
                _, v_lv_all = video_proj(vb_all)
                t_var = torch.exp(t_lv_all).mean().item()
                v_var = torch.exp(v_lv_all).mean().item()
                print(f"  [variance check] text={t_var:.4f}, video={v_var:.4f}")

        # save best
        if avg < best_loss:
            best_loss = avg
            # Convert learnable poly to dataclass when saving
            poly_surrogate = poly.to_surrogate()
            torch.save({
                "text_proj": text_proj.state_dict(),
                "video_proj": video_proj.state_dict(),
                "poly": {
                    "degree": poly_surrogate.degree,
                    "coeff": poly_surrogate.coeff,
                    "bias": poly_surrogate.bias,
                    "fit_logit": poly_surrogate.fit_logit,
                    "coeff_n": int(poly_surrogate.coeff.numel()),
                }
            }, Path(args.save_dir) / "best_projectors_eq4_poly.pth")
            print("  âœ“ saved best")

    print("Done. best_loss =", best_loss)
    print(f"\nSaved ckpt can be used in measure script:")
    print(f"  --ckpt {args.save_dir}/best_projectors_eq4_poly.pth")
    print(f"  (poly coefficients are included in ckpt, need to extract from ckpt during measure)")


# -----------------------------
# CLI
# -----------------------------
def build_argparser():
    ap = argparse.ArgumentParser()
    sub = ap.add_subparsers(dest="mode", required=True)

    # build_teacher
    s0 = sub.add_parser("build_teacher", help="MC teacher for Eq.(4) -> teacher.npz (ed,vd,y)")
    s0.add_argument("--npz", type=str, default=None, help="pcme_mu_logvar.npz with text_mu/logvar/video_mu/logvar (optional if --emb_dir given)")
    s0.add_argument("--emb_dir", type=str, default=None, help="dir with emb_text.pt and emb_video.pt (e.g. /mnt/pes/ImageBind/msrvtt_train_embeddings); used as mu with small fixed logvar if no --npz")
    s0.add_argument("--default_logvar", type=float, default=-5.0, help="fixed logvar when loading from --emb_dir (default -5 => var~0.007)")
    s0.add_argument("--out", type=str, required=True, help="output teacher npz")
    s0.add_argument("--K", type=int, default=8, help="MC samples per modality side (KxK pairs)")
    s0.add_argument("--n_pairs", type=int, default=200000, help="number of random text-video pairs")
    s0.add_argument("--a", type=float, default=0.1,
                    help="Eq4 parameter a. Use 0.1 so sigmoid(-a*E[d^2]+b) has spread; a=1 makes yâ‰ˆ0 for typical ed.")
    s0.add_argument("--b", type=float, default=0.0, help="Eq4 parameter b")
    s0.add_argument("--seed", type=int, default=0)

    # fit_poly
    s1 = sub.add_parser("fit_poly", help="Fit polynomial ridge on teacher -> poly_coeffs.pt")
    s1.add_argument("--teacher_npz", type=str, required=True)
    s1.add_argument("--out", type=str, required=True)
    s1.add_argument("--degree", type=int, default=4, help="poly degree (<=6 in this script)")
    s1.add_argument("--alpha", type=float, default=1e-3, help="Ridge alpha")
    s1.add_argument("--fit_logit", action="store_true", default=True, help="fit logit(y) instead of y")

    # train_poly
    s2 = sub.add_parser("train_poly", help="Train projectors with Eq4 polynomial logits (NO MC)")
    s2.add_argument("--emb_dir", type=str, default="/mnt/pes/ImageBind/msrvtt_train_embeddings",
                    help="dir containing emb_text.pt and emb_video.pt (default: /mnt/pes/ImageBind/msrvtt_train_embeddings)")
    s2.add_argument("--poly_path", type=str, required=True, help="poly_coeffs.pt from fit_poly")
    s2.add_argument("--save_dir", type=str, required=True)
    s2.add_argument("--epochs", type=int, default=40)
    s2.add_argument("--batch_size", type=int, default=64)
    s2.add_argument("--lr", type=float, default=1e-5)
    s2.add_argument("--hidden", type=int, default=2048)
    s2.add_argument("--temperature", type=float, default=0.07)

    s2.add_argument("--var_reg_type", type=str, choices=["none","kl","upper_bound"], default="upper_bound")
    s2.add_argument("--var_reg_weight", type=float, default=0.05)
    s2.add_argument("--max_var", type=float, default=0.09)
    s2.add_argument("--variance_check_every", type=int, default=5, help="0 disables variance check")
    s2.add_argument("--mu_loss_weight", type=float, default=0.0,
                    help="[Training only] mu contrastive loss weight. CIM inference still only computes (ed,vd)â†’poly, no mu similarity involved. Set 0.5 to improve retrieval.")

    # train_poly_e2e (end-to-end training, poly coefficients learnable)
    s3 = sub.add_parser("train_poly_e2e", help="End-to-end training of poly coefficients and projector (no need for teacher/fit_poly)")
    s3.add_argument("--emb_dir", type=str, default="/mnt/pes/ImageBind/msrvtt_train_embeddings",
                    help="dir containing emb_text.pt and emb_video.pt")
    s3.add_argument("--save_dir", type=str, required=True)
    s3.add_argument("--poly_degree", type=int, default=5, help="poly degree (<=6)")
    s3.add_argument("--init_poly", type=str, default=None,
                    help="Optional: initialize from existing poly_coeffs.pt (recommended! improves performance). Use heuristic initialization if not set.")
    s3.add_argument("--n_samples", type=int, default=5,
                    help="Monte Carlo sampling count (recommend 5, like baseline PCME). Set 0 for deterministic training (not recommended).")
    s3.add_argument("--epochs", type=int, default=40)
    s3.add_argument("--batch_size", type=int, default=64)
    s3.add_argument("--lr", type=float, default=1e-4, help="Learning rate (slightly higher than train_poly because need to learn poly coefficients)")
    s3.add_argument("--hidden", type=int, default=2048)
    s3.add_argument("--temperature", type=float, default=0.07)

    s3.add_argument("--var_reg_type", type=str, choices=["none","kl","upper_bound"], default="upper_bound")
    s3.add_argument("--var_reg_weight", type=float, default=0.05)
    s3.add_argument("--max_var", type=float, default=0.09)
    s3.add_argument("--variance_check_every", type=int, default=5, help="0 disables variance check")
    s3.add_argument("--mu_loss_weight", type=float, default=0.0,
                    help="[Training only] mu contrastive loss weight. CIM inference still only computes (ed,vd)â†’poly.")

    return ap


def main():
    ap = build_argparser()
    args = ap.parse_args()

    if args.mode == "build_teacher":
        mode_build_teacher(args)
    elif args.mode == "fit_poly":
        mode_fit_poly(args)
    elif args.mode == "train_poly":
        mode_train_poly(args)
    elif args.mode == "train_poly_e2e":
        mode_train_poly_e2e(args)
    else:
        raise ValueError(f"Unknown mode: {args.mode}")


if __name__ == "__main__":
    main()